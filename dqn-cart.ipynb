{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d8b52f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from dqn import DQN\n",
    "import torch as tr\n",
    "import gym\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e89f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "env = gym.make('CartPole-v1')\n",
    "qnet = DQN()\n",
    "loss = tr.nn.SmoothL1Loss()\n",
    "optimizer = tr.optim.RMSprop(qnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af9b6d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0865, -0.1742]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0764, -0.1872]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0664, -0.2002]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0662, -0.2005]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0664, -0.2000]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0669, -0.1989]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0663, -0.1952]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0659, -0.1912]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0656, -0.1868]], grad_fn=<AddmmBackward>) False\n",
      "tensor([[ 0.0656, -0.1821]], grad_fn=<AddmmBackward>) True\n"
     ]
    }
   ],
   "source": [
    "# loop over episode\n",
    "env.reset()\n",
    "\n",
    "max_ep_len = 20\n",
    "done = False\n",
    "tstep = 0\n",
    "env_out = env.step(0)\n",
    "while not done and tstep<max_ep_len:\n",
    "    obs_t,r_t,done,extra = env_out\n",
    "    (c_pos,c_vel,p_ang,p_vel) = obs_t\n",
    "    q_t = qnet(obs_t)\n",
    "    a_t = tr.argmax(q_t)\n",
    "    print(q_t,done)\n",
    "    tstep += 1 \n",
    "    env_out = env.step(a_t.detach().numpy())\n",
    "    \n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a9a12",
   "metadata": {},
   "source": [
    "# resources\n",
    "- [torch DQN tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)\n",
    "- [blog post](https://towardsdatascience.com/deep-q-learning-for-the-cartpole-44d761085c2f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
